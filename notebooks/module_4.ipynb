{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль 4: Рекуррентные нейронные сети (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что такое рекуррентные нейронные сети (RNN)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекуррентные нейронные сети (RNN)** — это тип нейронных сетей, предназначенных для работы с последовательными данными, такими как временные ряды, текст, аудио, видео и др. В отличие от стандартных полносвязных и сверточных сетей, RNN имеет возможность \"помнить\" информацию из предыдущих состояний, что позволяет учитывать контекст.  \n",
    "  \n",
    "Основная особенность RNN заключается в том, что они используют рекуррентную связь. На каждом шаге RNN получает входные данные и состояние из предыдущего шага, что позволяет модели обрабатывать последовательности данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные типы RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Простая RNN**: Первая версия сети, которая использует рекуррентные связи, но подвержена проблемам с затухающими и взрывными градиентами, что делает обучение долгим и сложным в случае длинных последовательностей.\n",
    "\n",
    "**LSTM (Long Short-Term Memory)**: Это более сложный тип RNN, который введен для решения проблем, связанных с простыми RNN. LSTM имеет специальные структуры — ячейки (cells), которые помогают сохранять информацию на длительное время благодаря механизмам управления, таким как \"входной\", \"выходной\" и \"выходной\" гейты. Это делает LSTM более эффективными для работы с длинными последовательностями.\n",
    "\n",
    "**GRU (Gated Recurrent Unit)**: Это более упрощенная версия LSTM, которая также использует механизмы врат, но с меньшим количеством параметров, что позволяет быстро обучаться и использовать меньше ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное применение RNN: Обработка последовательных данных. Например:\n",
    "1. Обработка естественного языка (NLP): машинный перевод, генерация текста, анализSentiment.\n",
    "2. Временные ряды: предсказание финансовых рынков, анализ сигнала, моделирование погодных условий.\n",
    "3. Аудио и музыка: генерация музыки, автоматическое распознавание речи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Затухающие градиенты** — это проблема, возникающая в глубоком обучении, когда градиенты, вычисляемые для обновления весов, становятся очень маленькими (близкими к нулю) по мере обратного распространения ошибки через множество слоев. Это приводит к тому, что:\n",
    " - Невозможность обучения: При очень маленьких градиентах обновление весов происходит очень медленно, особенно для нижних (или \"более ранних\") слоев сети. В результате они почти не обучаются, и сеть не может принимать правильные решения.\n",
    " - Проблемы с долгосрочной памятью: Это делает RNN, которые должны запоминать информацию на протяжении долгих последовательностей, менее эффективными, так как они теряют способность запоминать важные зависимости.\n",
    "  \n",
    "**Взрывные градиенты** — это противоположное явление, когда градиенты становятся очень большими по мере их распространения через сеть. Это может привести к:\n",
    " - Нестабильности обучения: Большие градиенты могут привести к резким изменениям весов, что вызывает колебания в значениях функции потерь и могут даже привести к \"разрушению\" модели.\n",
    " - Невозможность сходимости: Сеть может начать \"плясать\" около точки без сходимости, так как веса становятся слишком большими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Последовательные данные** — это данные, где порядок элементов имеет значение. Они представляют собой последовательности, в которых каждый элемент связан с предыдущими и последующими. Например:\n",
    "1. Временные ряды: Данные, собранные в последовательности во времени. Например, температура за день, цены акций, количество продаж по дням.\n",
    "2. Текст: Слова или символы, которые имеют последовательный порядок. Например, предложения, абзацы, языковые модели.\n",
    "3. Аудио: Звуковые волны, представленные во временной последовательности. Например, звук речи или музыки.\n",
    "4. Видео: Последовательность кадров, где каждый кадр зависит от предыдущего. Например, фильмы, записанные видеопотоки.\n",
    "5. Биологические последовательности: Данные в геномике, такие как последовательности нуклеотидов в ДНК.\n",
    "  \n",
    "**Непоследовательные данные**: Могут включать статические данные, такие как изображения или таблицы, где порядок элементов не имеет значения.\n",
    "  \n",
    "**Данные со структурами**: Могут включать графы, деревья и другие сложные структуры, в которых элементы могут иметь различные уровни взаимосвязи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Указание в качестве девайса GPU если доступна\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        num_epochs: int,\n",
    "        optimizer: torch.optim,\n",
    "        criterion: torch.nn,\n",
    "        train_dataloader: DataLoader\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): модель для обучения\n",
    "        num_epochs (int): кол-во итераций обучения\n",
    "        optimizer (torch.optim): оптимизатор\n",
    "        criterion (torch.nn): функция потерь\n",
    "        train_dataloader (torch.utils.data.DataLoader): загрузчик данных\n",
    "\n",
    "    Output:\n",
    "        loss_list (list): список значений функции потерь за каждый батч\n",
    "        acc_list (list): список точностей за каждый батч\n",
    "\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    # Кол-во обучающих премеров\n",
    "    train_amount = len(train_dataloader)\n",
    "\n",
    "    # Загрузка модели на GPU\n",
    "    model.train().to(device)\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for batch in tqdm(train_dataloader):\n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Перевод всех данных на GPU\n",
    "            data = batch[\"input_ids\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Предсказания модели\n",
    "            outputs = model(data)\n",
    "\n",
    "            # Расчет функции потерь\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Прибавление функции потерь к общей потере за эпоху\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Вычисление градиентов\n",
    "            loss.backward()\n",
    "\n",
    "            # Отпимизация весов на основе расчитанных градиентов\n",
    "            optimizer.step()\n",
    "\n",
    "            # Расчет точности (accuracy)\n",
    "            total = targets.shape[0]\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == targets).sum().item()\n",
    "            total_acc += correct / total\n",
    "        \n",
    "        # Расчет средней точности за эпоху\n",
    "        avg_loss = total_loss / train_amount\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        # Расчет средней точности за эпоху\n",
    "        avg_accuracy = total_acc / train_amount\n",
    "        acc_list.append(avg_accuracy)\n",
    "\n",
    "        # Вывод информации об эпохе обучения модели\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {avg_loss:.2f}, Accuracy: {avg_accuracy:.2f}')\n",
    "        print(\"=\" * 100)\n",
    "        print()\n",
    "\n",
    "    return loss_list, acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: nn.Module,\n",
    "    test_dataloader: DataLoader  \n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для оценки обученной модели.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): обученная модель\n",
    "        test_dataloader (DataLoader): даталодер для тестовых данных\n",
    "\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Оценка обученной модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            # Перевод всех данных на GPU\n",
    "            data = batch[\"input_ids\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.shape[0]\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the {} batch test texts: {} %'.format(len(test_dataloader), (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(example):\n",
    "    example[\"input_ids\"] = tokenizer(example[\"text\"], truncation=True, max_length=256)[\"input_ids\"]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализовать RNN для предсказания временных рядов\n",
    "\n",
    "С помощью синтетических или реальных данных, создать простую RNN для предсказания следующего значения в последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера задача: Классификация отзывов на фильмы c Кинопоиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета с отзывами\n",
    "dataset = load_dataset(\"ai-forever/kinopoisk-sentiment-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-conversational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка текстового датасета\n",
    "# 1. Токенизация предложений с помощью Токенизатора\n",
    "tokenized_dataset = dataset.map(tokenize_text, batched=True,\n",
    "                                remove_columns=[\"label_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Удаление лишнего класса ('1' - нейтральный отзыв)\n",
    "tokenized_dataset = tokenized_dataset.filter(lambda example: example[\"label\"] != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ddcdd7e507459a8060567a0bf6dd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7553a145b4b4a2696cfac39ebb1494d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7b7184b12f4efb854989c2f54e687d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Переименование класса '2' в '1'\n",
    "def rename_label(example):\n",
    "    if example[\"label\"] == 2:\n",
    "        example[\"label\"] = 1\n",
    "    return example\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(rename_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример текста: Если честно, меня не очень впечатлила новость, о том, что Гай Ричи собирается снять фильм, о Шерлоке Холмсе. Подумал — да это же будет: Карты, деньги, два ствола — у Холмса и у Ватсона. Но затем по мере появления трейлеров, и большей информации поменял своё отношение.\n",
      "«Шерлок Холмс» — последняя картина, на которую я планировал пойти в этом году. Жутко боялся, что она меня разочарует т. к. перед этим были расстроившие «Безумный спецназ», «Так себе каникулы» и немного 2012. Но Холмс полностью оправдал доверия.\n",
      "Сюжет\n",
      "В ленте динамичный, а главное интересный и захватывающий сюжет, что в последнее время не так уж и часто. Новый Холмс не поход классический образ представленный в картинах Игоря Масленникова, но это не портит его образ. Он больше подобен на Тони Старку из «Железного человека» или Грегори Хаусу из сериала «Доктор Хаус». Как и они, он весьма харизматичен, слегка безумен, но гениален в своём любимом деле.\n",
      "На первый взгляд сюжет портит сверхъестественное восстание из могилы лорда Блэквуда и другие необъяснимые вещи, но к концу всё становится на свои места. Кстати, в фильме отсутствуют некоторые моменты, присутствовавшие в трейлере. В современной версии не хватило места и выражению «Элементарно Ватсон!»\n",
      "Картинка и звук\n",
      "Режиссером стал Гай Ричи известный английский режиссер — создатель таких культовых фильмов как «Большой куш», «Карты, деньги, 2 ствола» и не плохого «Рок-н-рольщика». Его фильмы всегда впечатляют. И этот не исключение. Новый Холмс снят отлично. Картинка потрясающая — викторианский Лондон XIX века выглядит реалистично. А композитор Ханс Зиммер написал не плохую музыку к фильму.\n",
      "Игра актеров\n",
      "Роберт Дауни младший великолепно исполнил роль Холмса — сыграно красиво, интересно, с юмором. А Джуд Лоу — Ватсона. Да и вообще, актерская игра всех потрясающая и Рэйчел МакАдамс и Марка Стронга в том числе.\n",
      "Итог\n",
      "Предскажу, что кино больше понравится молодому поколению, а старшее посчитает фильм очередной попыткой переделать известного героя под современный мир или даже святотатством. Мне очень понравился, после просмотра замечено повышение настроения. Не пожалел что пошел, отличный фильм для зимних каникул, и рекомендую всем к просмотру.\n",
      "P.S. Жду продолжения и обязательно от Гая Ричи…\n",
      "\n",
      "Класс: Положительный\n"
     ]
    }
   ],
   "source": [
    "# 4. Визуализация данных\n",
    "class_dict = {0: \"Отрицательный\", 1: \"Положительный\"}\n",
    "text = tokenized_dataset[\"train\"][0][\"text\"]\n",
    "label = class_dict[tokenized_dataset[\"train\"][0][\"label\"]]\n",
    "print(\"Пример текста: {}\\n\".format(text))\n",
    "print(\"Класс: {}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Определение train, test, val datasets\n",
    "train_ds = tokenized_dataset[\"train\"].select(range(300))  # Первые 300 примеров\n",
    "val_ds = tokenized_dataset[\"validation\"].select(range(50))  # Следующие 50 примеров для валидации\n",
    "test_ds = tokenized_dataset[\"train\"].select(range(50))  # Следующие 50 примеров для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Оставляем только колонки input_ids и label\n",
    "train_ds = train_ds.select_columns([\"input_ids\", \"label\"])\n",
    "val_ds = val_ds.select_columns([\"input_ids\", \"label\"])\n",
    "test_ds = test_ds.select_columns([\"input_ids\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# 7. Создание DataLoaders\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 8. Визуализация размерности данных\n",
    "for batch in train_loader:\n",
    "    data = batch[\"input_ids\"]\n",
    "    targets = batch[\"labels\"]\n",
    "    print(data.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Определение модели RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        # Слой RNN\n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Прогон через слой эмбеддинга\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Прогон через RNN\n",
    "        output, hidden = self.rnn(x)\n",
    "        \n",
    "        # Прогон через полносвязный слой\n",
    "        out = self.fc(output[:, -1])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.78, Accuracy: 0.51\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5, Loss: 0.69, Accuracy: 0.58\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5, Loss: 0.60, Accuracy: 0.75\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5, Loss: 0.56, Accuracy: 0.69\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 42.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5, Loss: 0.45, Accuracy: 0.79\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Обучение модели\n",
    "model = RNN(vocab_size=tokenizer.vocab_size, embed_size=256, hidden_size=128, n_classes=2)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение\n",
    "loss_list, acc_list = train_model(model, 5, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 58.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 2 batch test texts: 76.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Оценка модели\n",
    "eval_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: Фильм отстой. Не советую смотреть.\n",
      "Предсказание: Отрицательный\n",
      "Вероятность ответа: 78.38%\n"
     ]
    }
   ],
   "source": [
    "# 12. Проверка модели на случайном примере\n",
    "text = \"Фильм отстой. Не советую смотреть.\"\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Текст: {text}\")\n",
    "    print(f\"Предсказание: {class_dict[predicted.item()]}\")\n",
    "    prob = torch.max(torch.softmax(outputs, dim=1)).item()\n",
    "    print(f\"Вероятность ответа: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат** - рассмотрена простейшая нейросеть архитектуры RNN. После обучения на 300 обучающих данных имеет точность в 76%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
